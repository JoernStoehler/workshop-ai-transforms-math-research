\documentclass[10pt,aspectratio=169]{beamer}
\usetheme{default}
\usecolortheme{default}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]
\usepackage{amsmath,amssymb}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% Simple color scheme
\definecolor{darkblue}{RGB}{0,51,102}
\definecolor{lightgray}{RGB}{240,240,240}
\setbeamercolor{title}{fg=darkblue}
\setbeamercolor{frametitle}{fg=darkblue}
\setbeamercolor{structure}{fg=darkblue}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{lightgray},
    frame=single,
    framerule=0pt,
    xleftmargin=5pt,
    xrightmargin=5pt
}

\title{Why \& How Does Few-Shot Learning Work?}
\subtitle{Transformers as Learning Algorithms}
\author{Jörn Stöhler (MSc Student) \and Claude (Research Assistant)}
\institute{University of Augsburg}
\date{}

\begin{document}

% Title slide
\begin{frame}
\titlepage
\end{frame}


% ==========================================
% SECTION 1: Introduction (2 min)
% ==========================================

\begin{frame}
\frametitle{What is Few-Shot Learning?}
\framesubtitle{Live Demonstration}

\begin{center}
\Large
Demo in ChatGPT.com
\end{center}

\vspace{1cm}

\begin{enumerate}
    \item Pattern completion: \texttt{"The cat sat on the mat. The dog sat on the..."}
    \item Zero-shot fails, few-shot succeeds
    \item Learning notation from examples
\end{enumerate}

\vspace{1cm}
\textbf{Key Question:} Examples transform behavior -- but how?
\end{frame}

% ==========================================
% SECTION 2: Benchmarks (2 min)
% ==========================================

\begin{frame}
\frametitle{Quantifying the Effect}
\framesubtitle{Benchmarks from GPT-3 Paper}

\begin{center}
\Large
\textbf{Open:} \href{papers/2005.14165_gpt3_language_models_few_shot.pdf}{\color{blue}GPT-3 Paper (Brown et al. 2020)}\\\small{\texttt{papers/2005.14165\_gpt3\_language\_models\_few\_shot.pdf}}
\end{center}

\vspace{0.5cm}
Show:
\begin{itemize}
    \item Figure 1.2: Performance vs parameters
    \item Figure 3.1: Zero/one/few-shot visual
    \item Figure 3.8: LAMBADA (76.2\% → 86.4\%)
\end{itemize}

\vspace{0.5cm}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
Model & Year & Zero-Shot & Few-Shot Gain \\
\hline
GPT-3 & 2020 & $\sim$50\% & +10-20pp \\
GPT-4 & 2023 & $\sim$80\% & +2-8pp \\
Current & 2024 & $\sim$85\% & +1-5pp \\
\hline
\end{tabular}
\end{center}
\end{frame}

\begin{frame}
\frametitle{SuperGLUE Results}
\framesubtitle{Few-Shot vs Fine-Tuning}

\begin{center}
\Large
\textbf{Open:} \href{papers/2005.14165_gpt3_language_models_few_shot.pdf}{\color{blue}GPT-3 Paper - SuperGLUE}\\\small{\texttt{papers/2005.14165\_gpt3\_language\_models\_few\_shot.pdf}}
\end{center}

\vspace{1cm}

Key Result:
\begin{itemize}
    \item GPT-3 (32-shot): 71.8\% (average)
    \item Fine-tuned BERT++: 69.8\% (average)
    \item \textbf{No gradient updates needed!}
\end{itemize}

\vspace{1cm}
\textit{Transition: The effect is real. Now let's understand the mechanism.}
\end{frame}

% ==========================================
% SECTION 3: Theory (2.5 min)
% ==========================================

\begin{frame}
\frametitle{Transformer Architecture}
\framesubtitle{Information Flow}

\begin{center}
\begin{tikzpicture}[scale=0.8]
    % Tokens
    \node at (0,0) {Tokens};
    \draw[->] (0.8,0) -- (2,0);
    
    % Embeddings
    \node at (3,0) {Embeddings};
    \node at (3,-0.5) {\small $a_0 \in \mathbb{R}^d$};
    \draw[->] (4.2,0) -- (5.5,0);
    
    % Layers
    \node[draw,minimum width=1.5cm,minimum height=0.8cm] at (6.5,0) {Layer 1};
    \node at (6.5,-0.5) {\small $a_1 = f_1(a_0)$};
    \draw[->] (7.5,0) -- (8.5,0);
    
    \node at (9,0) {$\cdots$};
    \draw[->] (9.5,0) -- (10.5,0);
    
    \node[draw,minimum width=1.5cm,minimum height=0.8cm] at (11.5,0) {Layer L};
    \node at (11.5,-0.5) {\small $a_L$};
    \draw[->] (12.5,0) -- (13.5,0);
    
    \node at (14.5,0) {Output};
    
    % Attention equation
    \node at (7,-2) {\Large $\text{Attention}(a) = \sum_t \text{softmax}(Q_t K_t^T) \cdot V_t$};
\end{tikzpicture}
\end{center}

\vspace{0.5cm}
Key Points:
\begin{itemize}
    \item Residual stream: Information highway
    \item Each layer reads ALL previous tokens
    \item Autoregressive: One token at a time
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Key Discovery}
\framesubtitle{Attention = Gradient Descent}

\begin{center}
\Large
\textbf{Open:} \href{papers/2212.07677_transformers_gradient_descent.pdf}{\color{blue}von Oswald et al. 2022}\\\small{\texttt{papers/2212.07677\_transformers\_gradient\_descent.pdf}}
\end{center}

\vspace{0.5cm}

\begin{block}{von Oswald et al. 2022 - Key Result}
\Large
For linear self-attention on regression:
\begin{equation*}
\text{Output} = \text{Input} + \eta \cdot \nabla_w \mathcal{L}
\end{equation*}
\end{block}

\vspace{0.3cm}
\textbf{Linear attention = exact gradient descent step}

\begin{itemize}
    \item Single layer = one gradient step (exact!)
    \item Multi-layer = preconditioned gradient descent
    \item Not approximation -- mathematically exact
\end{itemize}
\end{frame}

% ==========================================
% SECTION 4: Interpretability (2.5 min)
% ==========================================

\begin{frame}
\frametitle{What We've Found Inside}
\framesubtitle{Mechanistic Interpretability}

\textbf{1. Pattern Completion}
\begin{itemize}
    \item Attention patterns copy previous tokens
    \item Demonstrated in GPT models
    \item \textit{Note: Anthropic details online only}
\end{itemize}

\vspace{0.3cm}
\textbf{2. Function Vectors} 
\begin{itemize}
    \item Tasks encoded as activation directions
    \item \href{papers/2310.15213_function_vectors.pdf}{\color{blue}Todd et al. 2024}
    \item Can extract and compose task vectors
\end{itemize}

\vspace{0.3cm}
\textbf{3. Multiple Capabilities}
\begin{itemize}
    \item Models encode many tasks simultaneously
    \item Context selects relevant circuits
    \item Examples activate specific pathways
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Layer-Wise Processing}
\framesubtitle{Information Flow Through Depth}

\begin{center}
\Large
\textbf{Papers:} \href{papers/2211.15661_learning_algorithm.pdf}{\color{blue}Akyürek 2022} + \href{papers/2208.01066_what_can_transformers_learn.pdf}{\color{blue}Garg 2022}\\\small{\texttt{2211.15661 + 2208.01066}}
\end{center}

\vspace{0.5cm}

\textbf{Akyürek et al. findings:}
\begin{itemize}
    \item 1 layer: Single gradient descent step
    \item 2-3 layers: Multiple GD steps  
    \item 4+ layers: Ridge regression emerges
    \item Deep models: Approach closed-form solutions
\end{itemize}

\textit{Exact depth depends on task complexity}
\end{frame}

% ==========================================
% SECTION 5: Mathematical Constructions (2 min)
% ==========================================

\begin{frame}
\frametitle{What Can Transformers Provably Do?}
\framesubtitle{Mathematical Limits}

\textbf{What Papers Actually Prove:}
\begin{enumerate}
    \item \textbf{Linear attention = GD} -- \href{papers/2212.07677_transformers_gradient_descent.pdf}{\color{blue}von Oswald 2022}
    \item \textbf{Can implement ridge} -- \href{papers/2211.15661_learning_algorithm.pdf}{\color{blue}Akyürek 2022}
    \item \textbf{Learn linear functions} -- \href{papers/2208.01066_what_can_transformers_learn.pdf}{\color{blue}Garg 2022}
    \item \textbf{Hard attention is Turing complete} -- \href{papers/1901.03429_turing_completeness.pdf}{\color{blue}Pérez 2019}
\end{enumerate}

\vspace{0.5cm}
\textbf{Recent Result (2024):}
\begin{itemize}
    \item Prompting itself is Turing-complete
    \item \href{papers/2411.01992_prompting_turing_complete.pdf}{\color{blue}Paper: Prompting is Turing-complete (2024)}
\end{itemize}

\vspace{0.5cm}
\textbf{Memory Bounds:}
\begin{itemize}
    \item $\Theta(n)$ capacity for $n$ examples
    \item \href{papers/2405.13718_memory_capacity.pdf}{\color{blue}Tian et al. 2024}
\end{itemize}
\end{frame}

% ==========================================
% SECTION 6: Mesa-Optimization (2.5 min)
% ==========================================

\begin{frame}
\frametitle{Mesa-Optimization}
\framesubtitle{Two Optimization Loops}

\begin{center}
\Large
\textbf{Papers (both needed):}\\\href{papers/1906.01820_risks_learned_optimization.pdf}{\color{blue}[1] Hubinger 2019 - Terminology}\\\href{papers/2309.05858_mesa_optimization.pdf}{\color{blue}[2] von Oswald 2023 - Evidence}\\\href{papers/2405.16845_mesa_optimization_emergence.pdf}{\color{blue}[3] Zheng 2024 - Emergence}
\end{center}

\vspace{0.5cm}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
& \textbf{OUTER (Training)} & \textbf{INNER (Inference)} \\
\hline
Optimizer & SGD on parameters $\theta$ & Attention implements GD \\
\hline
Objective & Training loss & In-context loss \\
\hline
Updates & Weights & Activations \\
\hline
Time & Months & Single forward pass \\
\hline
\end{tabular}
\end{center}

\vspace{0.5cm}
\textbf{Critical insight:} Model learns HOW to learn, not just WHAT to predict

\vspace{0.3cm}
\textbf{Emerges without design!} Never explicitly trained for optimization
\end{frame}

\begin{frame}
\frametitle{Mesa-Optimization Evidence}
\framesubtitle{Internal Optimizer Discovery}

\begin{center}
\Large
\textbf{Open:} \href{papers/2309.05858_mesa_optimization.pdf}{\color{blue}Uncovering Mesa-Optimization}\\\small{\texttt{papers/2309.05858\_mesa\_optimization.pdf}}
\end{center}

\vspace{0.5cm}

Two-stage process discovered:
\begin{enumerate}
    \item \textbf{Early layers:} Preconditioning
    \item \textbf{Later layers:} Optimization on preconditioned problem
\end{enumerate}

\vspace{0.5cm}
Key findings:
\begin{itemize}
    \item Autoregressive training $\rightarrow$ internal optimizers
    \item Generalizes to unseen tasks
    \item Can extract the learned algorithm
\end{itemize}
\end{frame}

% ==========================================
% SECTION 7: Grad Student Analogy (1.5 min)
% ==========================================

\begin{frame}
\frametitle{Why Few-Shot Works}
\framesubtitle{The Grad Student Analogy}

\Large
\textbf{Few-shot learning $\approx$ Supervising grad students}

\vspace{0.5cm}
\normalsize
\begin{enumerate}
    \item \textbf{Examples provide new information}
    \begin{itemize}
        \item Your specific notation
        \item Not in training data
    \end{itemize}
    
    \item \textbf{Computable format}
    \begin{itemize}
        \item Examples $>$ descriptions
        \item Model runs gradient descent on them
    \end{itemize}
    
    \item \textbf{Disambiguate task}
    \begin{itemize}
        \item "Prove like Bourbaki, not Arnold"
    \end{itemize}
    
    \item \textbf{Knowledge loading (push system)}
    \begin{itemize}
        \item Examples activate circuits
        \item Weights $\rightarrow$ activations
    \end{itemize}
\end{enumerate}

\vspace{0.5cm}
\textit{Examples are training data for the internal optimizer!}
\end{frame}

% ==========================================
% Conclusion (0.5 min)
% ==========================================

\begin{frame}
\frametitle{Conclusion}
\framesubtitle{The Key Insight}

\begin{center}
\Large
\textbf{Few-shot learning works because transformers are computers that run learning algorithms}
\end{center}

\vspace{1cm}

\begin{itemize}
    \item Your examples are the \textbf{program}
    \item The forward pass is the \textbf{execution}
    \item The output is the result of \textbf{internal optimization}
\end{itemize}

\vspace{1cm}

\begin{center}
\textbf{This isn't metaphorical -- it's mathematically proven}
\end{center}
\end{frame}

% ==========================================
% Q&A Slide
% ==========================================

\begin{frame}
\frametitle{Questions?}
\framesubtitle{15-minute Q\&A -- Note: Some claims span multiple papers}

\Large
\textbf{Appendix Topics Available:}

\normalsize
\begin{itemize}
    \item A1: Detailed mechanistic interpretability
    \item A2: Statistical learning theory connection
    \item A3: Test-time training advances
    \item A4: Prompt engineering theory
    \item A5: Failure modes and limitations
\end{itemize}

\vspace{0.5cm}
\textbf{Key Papers (all in papers/ folder):}
\begin{itemize}
    \item \href{papers/2212.07677_transformers_gradient_descent.pdf}{\color{blue}von Oswald 2022} -- Gradient descent proof
    \item \href{papers/2309.05858_mesa_optimization.pdf}{\color{blue}von Oswald 2023} -- Mesa-optimization
    \item \href{papers/2211.15661_learning_algorithm.pdf}{\color{blue}Akyürek 2022} -- Algorithm identification  
    \item \href{papers/2208.01066_what_can_transformers_learn.pdf}{\color{blue}Garg 2022} -- What transformers learn
    \item \href{papers/1906.01820_risks_learned_optimization.pdf}{\color{blue}Hubinger 2019} -- Mesa terminology
\end{itemize}
\end{frame}

% ==========================================
% APPENDIX SLIDES (for Q&A)
% ==========================================

\begin{frame}
\frametitle{A1: Mechanistic Interpretability Details}
\framesubtitle{Circuit Discovery}

\textbf{Induction Heads:}
\begin{itemize}
    \item Previous token head + induction head
    \item Implements $[A][B] \ldots [A] \rightarrow [B]$
    \item Anthropic (2023) - web article
\end{itemize}

\vspace{0.5cm}
\textbf{Sparse Autoencoders:}
\begin{itemize}
    \item Extract monosemantic features
    \item Reveals superposition
    \item Anthropic (2024) - scaling study
\end{itemize}

\vspace{0.5cm}
\textbf{Knowledge Circuits:}
\begin{itemize}
    \item Early: Query formation
    \item Middle: Knowledge retrieval
    \item Late: Answer formatting
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{A2: Statistical Learning Theory}
\framesubtitle{Generalization Guarantees}

\textbf{Generalization Theory:}
\begin{itemize}
    \item Transformers satisfy PAC-learning bounds
    \item Algorithmic stability provides guarantees
    \item \textit{Li et al. 2023 (ICML proceedings)}
\end{itemize}

\vspace{0.5cm}
\textbf{Rademacher Complexity:}
\begin{itemize}
    \item Sequence-length independent bounds
    \item Explains why models don't overfit to examples
    \item Classical theory (VC dimension, Rademacher)
\end{itemize}

\vspace{0.5cm}
\textbf{Statistical Optimality:}
\begin{itemize}
    \item Achieves minimax rates for regression
    \item \href{papers/2408.12186_minimax_optimal.pdf}{\color{blue}2024 paper}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{A3: Test-Time Training}
\framesubtitle{Explicit Optimization at Inference}

\begin{center}
\Large
\textbf{Paper:} \href{papers/2503.11842_test_time_training.pdf}{\color{blue}Test-Time Training (2025)}
\end{center}

\vspace{0.5cm}

\textbf{Idea:} Gradient updates on context examples during inference

\vspace{0.5cm}
\textbf{Benefits:}
\begin{itemize}
    \item Combines parametric + non-parametric learning
    \item Better sample complexity
    \item Provable improvements
\end{itemize}

\vspace{0.5cm}
\textbf{Connection:} Makes mesa-optimization explicit!
\end{frame}

\begin{frame}
\frametitle{A4: Prompt Engineering Theory}
\framesubtitle{Optimal Example Selection}

\textbf{Example Selection Theory:}
\begin{itemize}
    \item Coverage vs similarity tradeoff
    \item Order matters for performance
    \item \textit{Multiple papers on selection strategies}
\end{itemize}

\vspace{0.5cm}
\textbf{Order Effects:}
\begin{itemize}
    \item Entropy ordering works best
    \item 17-point improvement on compositional tasks
    \item \href{papers/2402.07927_prompt_engineering_survey.pdf}{\color{blue}Survey paper}
\end{itemize}

\vspace{0.5cm}
\textbf{OPRO (LLMs as Optimizers):}
\begin{itemize}
    \item Natural language optimization
    \item 50\% improvement on reasoning
    \item \href{papers/2309.03409_llms_as_optimizers.pdf}{\color{blue}Yang et al. 2023}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{A5: Failure Modes}
\framesubtitle{When Few-Shot Doesn't Help}

\textbf{Limitations:}
\begin{enumerate}
    \item \textbf{Context window constraints}
    \begin{itemize}
        \item Memory: $\Theta(n)$ for $n$ examples
    \end{itemize}
    
    \item \textbf{Task misalignment}
    \begin{itemize}
        \item Mesa-objective $\neq$ your objective
    \end{itemize}
    
    \item \textbf{Distribution shift}
    \begin{itemize}
        \item Examples not representative
    \end{itemize}
    
    \item \textbf{Adversarial examples}
    \begin{itemize}
        \item Can hijack internal optimizer
    \end{itemize}
\end{enumerate}

\vspace{0.5cm}
\textbf{When it fails:}
\begin{itemize}
    \item Novel capabilities not in training
    \item Contradictory examples
    \item Tasks requiring true reasoning (not pattern matching)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Additional Resources}
\framesubtitle{For Further Reading}

\textbf{Core Papers:}
\begin{itemize}
    \item \href{papers/2005.14165_gpt3_language_models_few_shot.pdf}{\color{blue}GPT-3} -- Original few-shot benchmarks
    \item \href{papers/2303.08774_gpt4_technical_report.pdf}{\color{blue}GPT-4} -- Modern performance
    \item \href{papers/2309.16583_gpt_fathom.pdf}{\color{blue}GPT-Fathom} -- Model comparisons
\end{itemize}

\vspace{0.5cm}
\textbf{Theory Papers:}
\begin{itemize}
    \item \href{papers/1912.10077_universal_approximators.pdf}{\color{blue}Universal approximation}
    \item \href{papers/1901.03429_turing_completeness.pdf}{\color{blue}Turing completeness}
    \item \href{papers/2306.04637_transformers_statisticians.pdf}{\color{blue}Transformers as statisticians}
\end{itemize}

\vspace{0.5cm}
\textbf{Practical Guides (web):}
\begin{itemize}
    \item PromptHub few-shot guide (see papers/*.md)
    \item Analytics Vidhya comparison (see papers/*.md)
\end{itemize}
\end{frame}

\end{document}