# Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet

**Authors**: Templeton et al. 2024
**Source**: Transformer Circuits

**URL**: https://transformer-circuits.pub/2024/scaling-monosemanticity/

## Access this article

[Click here to read on Transformer Circuits](https://transformer-circuits.pub/2024/scaling-monosemanticity/)

## Summary from papers-summary.md

Continuation of monosemanticity work, scaling sparse autoencoders to extract interpretable features from Claude 3 Sonnet. Reveals how transformers encode thousands of concepts in lower dimensions through superposition.

## Note

This is an interactive web article with visualizations, not a downloadable PDF.